# ğŸ§ª Guia de Testes - WorcaFlow

Este documento descreve as convenÃ§Ãµes e prÃ¡ticas de teste do projeto.

---

## ğŸ“‹ **Ãndice**

1. [Estrutura de Testes](#estrutura-de-testes)
2. [ConvenÃ§Ãµes de Nomenclatura](#convenÃ§Ãµes-de-nomenclatura)
3. [PadrÃ£o AAA](#padrÃ£o-aaa)
4. [Tipos de Testes](#tipos-de-testes)
5. [Mocks e Fixtures](#mocks-e-fixtures)
6. [Cobertura de CÃ³digo](#cobertura-de-cÃ³digo)
7. [Executando Testes](#executando-testes)
8. [Definition of Done](#definition-of-done)

---

## ğŸ“ **Estrutura de Testes**

```
backend/tests/
â”œâ”€â”€ conftest.py              # ConfiguraÃ§Ãµes globais do pytest
â”œâ”€â”€ unit/                    # Testes unitÃ¡rios (isolados)
â”‚   â”œâ”€â”€ api/v1/core/
â”‚   â”œâ”€â”€ api/v1/services/
â”‚   â””â”€â”€ api/v1/models/
â”œâ”€â”€ integration/             # Testes de integraÃ§Ã£o
â”‚   â”œâ”€â”€ api/v1/routes/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ fixtures/                # Fixtures compartilhadas
â”‚   â”œâ”€â”€ mock_data.py        # Dados fake (Faker)
â”‚   â””â”€â”€ fake_services.py    # Fakes de serviÃ§os
â””â”€â”€ README.md
```

### **OrganizaÃ§Ã£o:**

- **`unit/`**: Testes que testam unidades isoladas (funÃ§Ãµes, classes, mÃ©todos)

  - NÃ£o dependem de banco de dados
  - NÃ£o dependem de rede
  - NÃ£o dependem de arquivos do sistema
  - Executam muito rÃ¡pido

- **`integration/`**: Testes que testam mÃºltiplas unidades trabalhando juntas

  - Podem usar mocks controlados
  - Testam fluxos completos
  - Podem depender de serviÃ§os fake

- **`fixtures/`**: Dados e serviÃ§os compartilhados
  - Factories de dados fake
  - Fakes de serviÃ§os (Supabase, ML, etc.)
  - Helpers para testes

---

## ğŸ·ï¸ **ConvenÃ§Ãµes de Nomenclatura**

### **Arquivos:**

```
test_<modulo>_<funcionalidade>.py
```

**Exemplos:**

- `test_auth_service.py` - Testes do serviÃ§o de autenticaÃ§Ã£o
- `test_orcamento_creation.py` - Testes de criaÃ§Ã£o de orÃ§amento
- `test_ml_price_prediction.py` - Testes de prediÃ§Ã£o de preÃ§os

### **Classes de Teste:**

```python
class Test<Modulo><Funcionalidade>:
    """DescriÃ§Ã£o do que estÃ¡ sendo testado"""
```

**Exemplos:**

```python
class TestAuthService:
    """Testes do serviÃ§o de autenticaÃ§Ã£o"""

class TestOrcamentoCreation:
    """Testes de criaÃ§Ã£o de orÃ§amentos"""
```

### **FunÃ§Ãµes de Teste:**

```python
def test_<acao>_<condicao>_<resultado_esperado>():
    """DescriÃ§Ã£o clara do teste"""
```

**Exemplos:**

```python
def test_login_with_valid_credentials_returns_token():
    """Testa que login com credenciais vÃ¡lidas retorna token"""

def test_create_orcamento_with_invalid_data_raises_error():
    """Testa que criar orÃ§amento com dados invÃ¡lidos levanta erro"""
```

---

## ğŸ¯ **PadrÃ£o AAA (Arrange, Act, Assert)**

Sempre organize seus testes no padrÃ£o AAA:

```python
def test_example():
    # ARRANGE - Preparar dados e ambiente
    user_data = create_fake_user_data()
    service = AuthService()

    # ACT - Executar aÃ§Ã£o sendo testada
    result = service.create_user(user_data)

    # ASSERT - Verificar resultado
    assert result is not None
    assert result["email"] == user_data["email"]
```

### **Exemplo Completo:**

```python
import pytest
from backend.tests.fixtures.mock_data import create_fake_user_data
from backend.api.v1.services.auth_service import AuthService

class TestAuthService:
    def test_create_user_success(self):
        # ARRANGE
        user_data = create_fake_user_data()
        service = AuthService()

        # ACT
        result = service.create_user(user_data)

        # ASSERT
        assert result is not None
        assert "id" in result
        assert result["email"] == user_data["email"]

    def test_create_user_with_duplicate_email_raises_error(self):
        # ARRANGE
        user_data = create_fake_user_data()
        service = AuthService()
        service.create_user(user_data)  # Primeiro usuÃ¡rio

        # ACT & ASSERT
        with pytest.raises(ValueError, match="Email jÃ¡ cadastrado"):
            service.create_user(user_data)  # Segundo usuÃ¡rio (duplicado)
```

---

## ğŸ“Š **Tipos de Testes**

### **1. Testes UnitÃ¡rios (`@pytest.mark.unit`)**

Testam unidades isoladas sem dependÃªncias externas.

```python
import pytest

@pytest.mark.unit
def test_validate_email_valid():
    """Testa validaÃ§Ã£o de email vÃ¡lido"""
    from backend.api.v1.core.validators import validate_email

    assert validate_email("teste@example.com") == True
```

### **2. Testes de IntegraÃ§Ã£o (`@pytest.mark.integration`)**

Testam mÃºltiplas unidades trabalhando juntas.

```python
@pytest.mark.integration
def test_create_solicitacao_flow():
    """Testa fluxo completo de criaÃ§Ã£o de solicitaÃ§Ã£o"""
    # Testa serviÃ§o + modelo + validaÃ§Ã£o juntos
    ...
```

### **3. Testes E2E (`@pytest.mark.e2e`)**

Testam fluxos completos end-to-end.

```python
@pytest.mark.e2e
def test_fluxo_completo_solicitacao_orcamento():
    """Testa fluxo: solicitaÃ§Ã£o â†’ orÃ§amento â†’ aceite"""
    ...
```

### **4. Testes Lentos (`@pytest.mark.slow`)**

Testes que demoram para executar.

```python
@pytest.mark.slow
def test_ml_model_training():
    """Testa treinamento completo do modelo ML"""
    ...
```

**Executar apenas testes rÃ¡pidos:**

```bash
pytest -m "not slow"
```

---

## ğŸ­ **Mocks e Fixtures**

### **Usando Fixtures do Pytest:**

```python
# conftest.py
import pytest
from backend.tests.fixtures.fake_services import FakeSupabaseService

@pytest.fixture
def fake_supabase():
    """Fixture que fornece fake do Supabase"""
    service = FakeSupabaseService()
    yield service
    service.clear()  # Limpa apÃ³s teste
```

**Usando a fixture:**

```python
def test_create_user_with_fake_supabase(fake_supabase):
    """Testa criaÃ§Ã£o de usuÃ¡rio usando fake do Supabase"""
    # ARRANGE
    service = AuthService(database=fake_supabase)
    user_data = create_fake_user_data()

    # ACT
    result = service.create_user(user_data)

    # ASSERT
    assert result is not None
```

### **Usando Mocks (pytest-mock):**

```python
from unittest.mock import Mock, patch

def test_ml_prediction_with_mock(mocker):
    """Testa prediÃ§Ã£o de ML com mock"""
    # ARRANGE
    mock_ml_service = Mock()
    mock_ml_service.predict_price.return_value = 500.0

    # ACT
    result = some_function_that_uses_ml(mock_ml_service)

    # ASSERT
    assert result == 500.0
    mock_ml_service.predict_price.assert_called_once()
```

### **Dados Fake (Faker):**

```python
from backend.tests.fixtures.mock_data import (
    create_fake_user_data,
    create_fake_orcamento_data,
    create_fake_solicitacao_data
)

def test_example():
    user_data = create_fake_user_data()
    orcamento_data = create_fake_orcamento_data()
    # ...
```

---

## ğŸ“ˆ **Cobertura de CÃ³digo**

### **Objetivos de Cobertura:**

- **MÃ­nimo**: 70% nas unidades modificadas
- **Ideal**: 80%+ em todo o cÃ³digo
- **CrÃ­tico**: 90%+ (autenticaÃ§Ã£o, pagamentos, ML)

### **Executar com Cobertura:**

```bash
# Cobertura completa
pytest --cov=api --cov-report=html --cov-report=term

# Ver relatÃ³rio HTML
open htmlcov/index.html  # Linux/Mac
start htmlcov/index.html  # Windows
```

### **Verificar Cobertura MÃ­nima:**

```bash
pytest --cov=api --cov-report=term --cov-fail-under=70
```

### **Excluir Linhas da Cobertura:**

```python
def some_function():
    # pragma: no cover
    if DEBUG_MODE:
        print("Debug info")
```

---

## ğŸš€ **Executando Testes**

### **Todos os Testes:**

```bash
cd backend
pytest
```

### **Testes EspecÃ­ficos:**

```bash
# Por arquivo
pytest tests/unit/api/v1/services/test_auth_service.py

# Por funÃ§Ã£o
pytest tests/unit/api/v1/services/test_auth_service.py::TestAuthService::test_create_user

# Por marcador
pytest -m unit          # Apenas unitÃ¡rios
pytest -m integration   # Apenas integraÃ§Ã£o
pytest -m "not slow"    # Excluir lentos
```

### **Com Verbosidade:**

```bash
pytest -v              # Verboso
pytest -vv             # Muito verboso
pytest -s              # Mostrar prints
```

### **Com Cobertura:**

```bash
pytest --cov=api --cov-report=html
```

### **Paralelo (mais rÃ¡pido):**

```bash
pip install pytest-xdist
pytest -n auto  # Usa todos os CPUs disponÃ­veis
```

---

## âœ… **Definition of Done (DoD)**

### **Para cada PR/Merge:**

- [ ] âœ… Todos os testes passando (`pytest`)
- [ ] âœ… Cobertura >70% nas unidades modificadas
- [ ] âœ… CI/CD pipeline verde
- [ ] âœ… Sem linter errors (flake8, black)
- [ ] âœ… DocumentaÃ§Ã£o atualizada
- [ ] âœ… Code review aprovado

### **Para cada Feature:**

- [ ] âœ… Testes unitÃ¡rios escritos (TDD quando possÃ­vel)
- [ ] âœ… Testes de integraÃ§Ã£o para fluxos crÃ­ticos
- [ ] âœ… DocumentaÃ§Ã£o de API atualizada
- [ ] âœ… Exemplos de uso

### **Para cada Bugfix:**

- [ ] âœ… Teste que reproduz o bug (RED)
- [ ] âœ… Teste passando apÃ³s correÃ§Ã£o (GREEN)
- [ ] âœ… RefatoraÃ§Ã£o se necessÃ¡rio (REFACTOR)

---

## ğŸ“ **Boas PrÃ¡ticas**

### **âœ… FAZER:**

1. **Um assert por teste** (quando possÃ­vel)

   ```python
   def test_something():
       result = function()
       assert result.status == "success"
       assert result.code == 200
   ```

2. **Testes independentes** (sem ordem)

   ```python
   # Cada teste deve funcionar isoladamente
   def test_a(): ...
   def test_b(): ...  # NÃ£o depende de test_a
   ```

3. **Nomes descritivos**

   ```python
   # âœ… BOM
   def test_login_with_invalid_password_raises_error():

   # âŒ RUIM
   def test_login():
   ```

4. **Usar fixtures para setup comum**

   ```python
   @pytest.fixture
   def user_service():
       return UserService()
   ```

5. **Mockar dependÃªncias externas**
   ```python
   # Mockar Supabase, HTTP, arquivos
   ```

### **âŒ EVITAR:**

1. **Testes que dependem uns dos outros**

   ```python
   # âŒ RUIM - test_b depende de test_a
   def test_a():
       global x
       x = 1

   def test_b():
       assert x == 1  # Falha se test_a nÃ£o rodar primeiro
   ```

2. **Testes muito complexos**

   ```python
   # âŒ RUIM - testa muitas coisas
   def test_everything():
       # 100 linhas de cÃ³digo...
   ```

3. **Dados hardcoded**

   ```python
   # âŒ RUIM
   email = "teste@teste.com"

   # âœ… BOM
   user_data = create_fake_user_data()
   email = user_data["email"]
   ```

4. **Ignorar testes que falham**
   ```python
   # âŒ RUIM
   @pytest.mark.skip(reason="NÃ£o funciona")
   def test_something(): ...
   ```

---

## ğŸ“š **Recursos**

- [pytest documentation](https://docs.pytest.org/)
- [FastAPI Testing](https://fastapi.tiangolo.com/tutorial/testing/)
- [Testing Best Practices](https://realpython.com/python-testing/)
- [TDD Guide](https://martinfowler.com/bliki/TestDrivenDevelopment.html)

---

**Ãšltima atualizaÃ§Ã£o**: 2025-01-XX
